{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 21:54:35.405088: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-15 21:54:36.228071: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: attrs in /home/pidoux/.local/lib/python3.10/site-packages (23.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.16MB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.48MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 280kB/s] \n",
      "100%|██████████| 9.91M/9.91M [00:07<00:00, 1.27MB/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import datetime\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "#%pip install --upgrade attrs\n",
    "\n",
    "\n",
    "\n",
    "# Téléchargement des données\n",
    "\n",
    "from datamaestro import prepare_dataset\n",
    "ds = prepare_dataset(\"com.lecun.mnist\");\n",
    "train_images, train_labels = ds.train.images.data(), ds.train.labels.data()\n",
    "test_images, test_labels =  ds.test.images.data(), ds.test.labels.data()\n",
    "\n",
    "# Tensorboard : rappel, lancer dans une console tensorboard --logdir runs\n",
    "writer = SummaryWriter(\"runs/runs\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "# Pour visualiser\n",
    "# Les images doivent etre en format Channel (3) x Hauteur x Largeur\n",
    "images = torch.tensor(train_images[0:8]).unsqueeze(1).repeat(1,3,1,1).double()/255.\n",
    "# Permet de fabriquer une grille d'images\n",
    "images = make_grid(images)\n",
    "# Affichage avec tensorboard\n",
    "writer.add_image(f'samples', images, 0)\n",
    "\n",
    "\n",
    "savepath = Path(\"model.pch\")\n",
    "\n",
    "\n",
    "class MonDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        label = self.labels[index]\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(test_images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "size :  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pidoux/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:171: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 \tLoss: 0.205389\n",
      "Train Epoch: 1 \tLoss: 0.117593\n",
      "Train Epoch: 2 \tLoss: 0.103722\n",
      "Train Epoch: 3 \tLoss: 0.061561\n",
      "Train Epoch: 4 \tLoss: 0.019130\n",
      "Train Epoch: 5 \tLoss: 0.006933\n",
      "Train Epoch: 6 \tLoss: 0.064064\n",
      "Train Epoch: 7 \tLoss: 0.143901\n",
      "Train Epoch: 8 \tLoss: 0.008265\n",
      "Train Epoch: 9 \tLoss: 0.005987\n",
      "\n",
      "size :  128\n",
      "Train Epoch: 0 \tLoss: 0.196057\n",
      "Train Epoch: 1 \tLoss: 0.137015\n",
      "Train Epoch: 2 \tLoss: 0.067686\n",
      "Train Epoch: 3 \tLoss: 0.098804\n",
      "Train Epoch: 4 \tLoss: 0.105168\n",
      "Train Epoch: 5 \tLoss: 0.090326\n",
      "Train Epoch: 6 \tLoss: 0.127438\n",
      "Train Epoch: 7 \tLoss: 0.093357\n",
      "Train Epoch: 8 \tLoss: 0.173756\n",
      "Train Epoch: 9 \tLoss: 0.048117\n",
      "\n",
      "size :  256\n",
      "Train Epoch: 0 \tLoss: 0.254771\n",
      "Train Epoch: 1 \tLoss: 0.189312\n",
      "Train Epoch: 2 \tLoss: 0.222605\n",
      "Train Epoch: 3 \tLoss: 0.180836\n",
      "Train Epoch: 4 \tLoss: 0.208006\n",
      "Train Epoch: 5 \tLoss: 0.137836\n",
      "Train Epoch: 6 \tLoss: 0.062540\n",
      "Train Epoch: 7 \tLoss: 0.068545\n",
      "Train Epoch: 8 \tLoss: 0.027037\n",
      "Train Epoch: 9 \tLoss: 0.029131\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_sizes = [32, 128, 256]\n",
    "log_interval = 100\n",
    "\n",
    "input_size = 28 * 28  \n",
    "hidden_size = 128  \n",
    "output_size = 10  \n",
    "\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    print(\"\\nsize : \", batch_size)\n",
    "    train_loader = DataLoader(MonDataset(train_images, train_labels), batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(input_size, hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_size, output_size)\n",
    "    )\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()  \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images = images.reshape(-1, 28 * 28)/255.\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'avantage de l'initialisation des poids du décodeur avec la transposée des poids de l'encodeur est que cela aide le modèle à converger plus rapidement. En utilisant cette initialisation, le décodeur est initialement proche de l'inverse de l'encodeur, ce qui permet une meilleure reconstruction des données lors de l'apprentissage. Cela peut accélérer la convergence de l'autoencodeur lors de l'apprentissage non supervisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, encoding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        # Transposez les poids de l'encodeur et copiez-les dans le décodeur\n",
    "        for enc_layer, dec_layer in zip(self.encoder, self.decoder):\n",
    "            if isinstance(enc_layer, nn.Linear) and isinstance(dec_layer, nn.Linear):\n",
    "                dec_layer.weight.data = enc_layer.weight.data.T\n",
    "                dec_layer.bias.data = enc_layer.bias.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder_sans_init(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(Autoencoder_sans_init, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, encoding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:23<00:00,  2.87s/it]\n"
     ]
    }
   ],
   "source": [
    "#parametre du modele\n",
    "input_dim = 784  \n",
    "encoding_dim = 32 \n",
    "n_hidden = 20\n",
    "lr = 0.01\n",
    "batch_size = 100\n",
    "iterations = 50\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# data loader pour les données d'entrainement et de test\n",
    "\n",
    "train_loader = DataLoader(MonDataset(train_images, train_labels), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(MonDataset(test_images, test_labels), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# device\n",
    "device = torch.device( 'cuda' if torch.cuda.is_available() else 'cpu' )\n",
    "print(f\"running on {device}\")\n",
    "\n",
    "\n",
    "class State :\n",
    "    def __init__(self, model, optim) :\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.epoch, self.iteration = 0,0\n",
    "# charger un état précédent\n",
    "savepath=Path(\"model5.pch\")\n",
    "if savepath.is_file():\n",
    "    with savepath.open(\"rb\") as fp:\n",
    "        state = torch.load(fp)\n",
    "#creer un nouvel état à partir d'un modèle et d'un optimiseur\n",
    "else:\n",
    "    model = Autoencoder_sans_init(input_dim, encoding_dim)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    state = State(model, optimizer)\n",
    "\n",
    "for epoch in tqdm(range(iterations)):\n",
    "    for x,y in train_loader:\n",
    "        x = x.reshape(-1, 28 * 28)/255.\n",
    "        state.optim.zero_grad()\n",
    "        x = x.to(device)\n",
    "        encoded , outputs = state.model(x)\n",
    "        loss = criterion(outputs, x)\n",
    "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "        loss.backward()\n",
    "        state.optim.step()\n",
    "        state.iteration += 1\n",
    "    with savepath.open(\"wb\") as fp:\n",
    "        state.epoch += 1\n",
    "        torch.save(state, fp)\n",
    "    with torch.no_grad():\n",
    "        for x, _ in test_loader:\n",
    "            x = x.reshape(-1, 28 * 28)/255.\n",
    "            x = x.to(device)\n",
    "            encoded_test, outputs_test = model(x)\n",
    "            loss_test = criterion(outputs_test, x)\n",
    "            writer.add_scalar(\"Loss/test\", loss_test, epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x avant encodage\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x apres encodage\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x apres decodage\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with torch.no_grad():\n",
    "    i=0\n",
    "    for x, _ in test_loader:\n",
    "        x = x.reshape(-1, 28 * 28)/255\n",
    "        if i==0:\n",
    "            print('x avant encodage')\n",
    "            plt.imshow(x[0].reshape(28,28).to(\"cpu\"))\n",
    "            plt.show()\n",
    "            i+=1\n",
    "        x = x.to(device)\n",
    "        encoded , outputs = model(x)\n",
    "    print('x apres encodage')\n",
    "    plt.imshow(encoded[0].reshape(4,8).to(\"cpu\"))\n",
    "    plt.show()\n",
    "    print('x apres decodage')\n",
    "    plt.imshow(outputs[0].reshape(28,28).to(\"cpu\"))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/tmp/ipykernel_43089/2173379003.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  image = torch.tensor(x[0:8].to('cpu')).unsqueeze(1).reshape(8,1,28,28).repeat(1,3,1,1)\n",
      "/tmp/ipykernel_43089/2173379003.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  image = torch.tensor(outputs_test[0:8].to('cpu')).unsqueeze(1).reshape(8,1,28,28).repeat(1,3,1,1)\n",
      "100%|██████████| 10/10 [00:33<00:00,  3.38s/it]\n"
     ]
    }
   ],
   "source": [
    "#parametre du modele\n",
    "input_dim = 784  \n",
    "encoding_dim = 32 \n",
    "n_hidden = 20\n",
    "lr = 0.01\n",
    "batch_size = 100\n",
    "iterations = 10\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# data loader pour les données d'entrainement et de test\n",
    "\n",
    "train_loader = DataLoader(MonDataset(train_images, train_labels), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(MonDataset(test_images, test_labels), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# device\n",
    "device = torch.device( 'cuda' if torch.cuda.is_available() else 'cpu' )\n",
    "print(f\"running on {device}\")\n",
    "\n",
    "\n",
    "class State :\n",
    "    def __init__(self, model, optim) :\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.epoch, self.iteration = 0,0\n",
    "# charger un état précédent\n",
    "savepath=Path(\"model6.pch\")\n",
    "if savepath.is_file():\n",
    "    with savepath.open(\"rb\") as fp:\n",
    "        state = torch.load(fp)\n",
    "#creer un nouvel état à partir d'un modèle et d'un optimiseur\n",
    "else:\n",
    "    model = Autoencoder(input_dim, encoding_dim)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    state = State(model, optimizer)\n",
    "\n",
    "for epoch in tqdm(range(iterations)):\n",
    "    for x,y in train_loader:\n",
    "        x = x.reshape(-1, 28 * 28)/255.\n",
    "        state.optim.zero_grad()\n",
    "        x = x.to(device)\n",
    "        encoded , outputs = state.model(x)\n",
    "        loss = criterion(outputs, x)\n",
    "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "        loss.backward()\n",
    "        state.optim.step()\n",
    "        state.iteration += 1\n",
    "    with savepath.open(\"wb\") as fp:\n",
    "        state.epoch += 1\n",
    "        torch.save(state, fp)\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        for x, _ in test_loader:\n",
    "            x = x.reshape(-1, 28 * 28)/255.\n",
    "            x = x.to(device)\n",
    "            encoded_test, outputs_test = model(x)\n",
    "            loss_test = criterion(outputs_test, x)\n",
    "            writer.add_scalar(\"Loss/test\", loss_test, epoch)\n",
    "\n",
    "            image = torch.tensor(x[0:8].to('cpu')).unsqueeze(1).reshape(8,1,28,28).repeat(1,3,1,1)\n",
    "            writer.add_images(f'samples', image, epoch)\n",
    "            image = torch.tensor(outputs_test[0:8].to('cpu')).unsqueeze(1).reshape(8,1,28,28).repeat(1,3,1,1)\n",
    "            writer.add_images(f'decoded', image, epoch)\n",
    "            embedding = torch.tensor(outputs_test[0:8].to('cpu')).unsqueeze(1).reshape(8,1,28,28).repeat(1,3,1,1)\n",
    "            writer.add_embedding(embedding, global_step = epoch, tag = f'encoded')\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
