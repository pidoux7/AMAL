{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lydia\\OneDrive\\Documents\\AMAL\\student_tp8\\src\\tme8.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lydia/OneDrive/Documents/AMAL/student_tp8/src/tme8.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Utiliser tp8_preprocess pour générer le vocabulaire BPE et\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lydia/OneDrive/Documents/AMAL/student_tp8/src/tme8.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# le jeu de donnée dans un format compact\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lydia/OneDrive/Documents/AMAL/student_tp8/src/tme8.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lydia/OneDrive/Documents/AMAL/student_tp8/src/tme8.ipynb#W1sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# --- Configuration\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lydia/OneDrive/Documents/AMAL/student_tp8/src/tme8.ipynb#W1sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lydia/OneDrive/Documents/AMAL/student_tp8/src/tme8.ipynb#W1sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Taille du vocabulaire\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lydia/OneDrive/Documents/AMAL/student_tp8/src/tme8.ipynb#W1sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m vocab_size \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lydia/OneDrive/Documents/AMAL/student_tp8/src/tme8.ipynb#W1sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m MAINDIR \u001b[39m=\u001b[39m Path(\u001b[39m__file__\u001b[39;49m)\u001b[39m.\u001b[39mparent\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lydia/OneDrive/Documents/AMAL/student_tp8/src/tme8.ipynb#W1sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Chargement du tokenizer\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lydia/OneDrive/Documents/AMAL/student_tp8/src/tme8.ipynb#W1sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m spm\u001b[39m.\u001b[39mSentencePieceProcessor()\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from torch.nn.modules.pooling import MaxPool1d\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import heapq\n",
    "from pathlib import Path\n",
    "import gzip\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sentencepiece as spm\n",
    "\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tp8_preprocess import TextDataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Datasets: train=1599000, val=1000, test=359\n",
      "INFO:root:Vocabulary size: 1000\n"
     ]
    }
   ],
   "source": [
    "# Utiliser tp8_preprocess pour générer le vocabulaire BPE et\n",
    "# le jeu de donnée dans un format compact\n",
    "\n",
    "# --- Configuration\n",
    "\n",
    "# Taille du vocabulaire\n",
    "vocab_size = 1000\n",
    "MAINDIR = Path(\"./\").parent\n",
    "\n",
    "# Chargement du tokenizer\n",
    "\n",
    "tokenizer = spm.SentencePieceProcessor()\n",
    "tokenizer.Load(f\"wp{vocab_size}.model\")\n",
    "ntokens = len(tokenizer)\n",
    "\n",
    "def loaddata(mode):\n",
    "    with gzip.open(f\"{mode}-{vocab_size}.pth\", \"rb\") as fp:\n",
    "        return torch.load(fp)\n",
    "\n",
    "\n",
    "test = loaddata(\"test\")\n",
    "train = loaddata(\"train\")\n",
    "TRAIN_BATCHSIZE=500\n",
    "TEST_BATCHSIZE=500\n",
    "\n",
    "\n",
    "# --- Chargements des jeux de données train, validation et test\n",
    "\n",
    "val_size = 1000\n",
    "train_size = len(train) - val_size\n",
    "train, val = torch.utils.data.random_split(train, [train_size, val_size])\n",
    "\n",
    "logging.info(\"Datasets: train=%d, val=%d, test=%d\", train_size, val_size, len(test))\n",
    "logging.info(\"Vocabulary size: %d\", vocab_size)\n",
    "train_iter = torch.utils.data.DataLoader(train, batch_size=TRAIN_BATCHSIZE, collate_fn=TextDataset.collate)\n",
    "val_iter = torch.utils.data.DataLoader(val, batch_size=TEST_BATCHSIZE, collate_fn=TextDataset.collate)\n",
    "test_iter = torch.utils.data.DataLoader(test, batch_size=TEST_BATCHSIZE, collate_fn=TextDataset.collate)\n",
    "\n",
    "\n",
    "#  TODO: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lydia\\OneDrive\\Documents\\AMAL\\student_tp8\\src\\tme8.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lydia/OneDrive/Documents/AMAL/student_tp8/src/tme8.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m, train[\u001b[39m0\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lydia/OneDrive/Documents/AMAL/student_tp8/src/tme8.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m, val[\u001b[39m0\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lydia/OneDrive/Documents/AMAL/student_tp8/src/tme8.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, test[\u001b[39m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"train\", train[0])\n",
    "print(\"val\", val[0])\n",
    "print(\"test\", test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO tester a partir d'ici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_filters, filter_sizes, num_classes):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(1, num_filters, (fs, embedding_dim)) for fs in filter_sizes\n",
    "        ])\n",
    "        self.fc = nn.Linear(len(filter_sizes) * num_filters, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # Embedding layer\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        x = [torch.relu(conv(x)).squeeze(3) for conv in self.convs]  # Convolutional layers\n",
    "        x = [torch.max_pool1d(conv, conv.size(2)).squeeze(2) for conv in x]  # Max pooling layers\n",
    "        x = torch.cat(x, 1)  # Concatenate results from different filter sizes\n",
    "        x = self.fc(x)  # Fully connected layer\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MajorityClassBaseline:\n",
    "    def __init__(self, majority_class=None):\n",
    "        self.majority_class = majority_class\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the baseline model.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input data (not used in this baseline)\n",
    "        - y: Target labels (used to determine the majority class)\n",
    "        \"\"\"\n",
    "        if self.majority_class is None:\n",
    "            # Determine the majority class if not explicitly provided\n",
    "            unique_classes, counts = torch.unique(y, return_counts=True)\n",
    "            self.majority_class = unique_classes[counts.argmax()]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions using the baseline model.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input data (not used in this baseline)\n",
    "\n",
    "        Returns:\n",
    "        - predictions: Predicted labels (always the majority class)\n",
    "        \"\"\"\n",
    "        if self.majority_class is None:\n",
    "            raise ValueError(\"Majority class is not set. Fit the model with training data first or provide it explicitly.\")\n",
    "        \n",
    "        # Return predictions of the majority class\n",
    "        predictions = torch.full((len(X),), self.majority_class, dtype=torch.long)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_class_baseline = MajorityClassBaseline()\n",
    "majority_class_baseline.fit(train, train.labels)\n",
    "predictions = majority_class_baseline.predict(test)\n",
    "print(\"Majority class baseline accuracy:\", (predictions == test.labels).float().mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Metrics for Baseline Model (if available)\n",
    "baseline_val_predictions = majority_class_baseline.predict(val)  # Use your baseline model\n",
    "baseline_val_accuracy = accuracy_score(val.labels, baseline_val_predictions)\n",
    "baseline_val_precision = precision_score(val.labels, baseline_val_predictions)\n",
    "baseline_val_recall = recall_score(val.labels, baseline_val_predictions)\n",
    "baseline_val_f1 = f1_score(val.labels, baseline_val_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Confusion Matrices\n",
    "confusion_matrix_cnn = confusion_matrix(val.labels, baseline_val_predictions)\n",
    "confusion_matrix_baseline = confusion_matrix(val.labels, baseline_val_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = ntokens\n",
    "embedding_dim = 100\n",
    "num_filters = 100\n",
    "filter_sizes = [3, 4, 5]\n",
    "num_classes = 3\n",
    "model1 = TextCNN(vocab_size, embedding_dim, num_filters, filter_sizes, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model1.parameters(), lr=learning_rate)\n",
    "\n",
    "# Step 1b: Training Loop\n",
    "for epoch in range(epochs):\n",
    "    model1.train()\n",
    "    for batch in train_iter:\n",
    "        inputs, labels = batch.text.to(device), batch.labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model1(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Step 1c: Evaluate on Validation Dataset\n",
    "model1.eval()\n",
    "val_predictions = []\n",
    "val_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in val_iter:\n",
    "        inputs, labels = batch.text.to(device), batch.labels.to(device)\n",
    "        outputs = model1(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        val_predictions.extend(predicted.cpu().numpy())\n",
    "        val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate validation metrics\n",
    "val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "val_precision = precision_score(val_labels, val_predictions)\n",
    "val_recall = recall_score(val_labels, val_predictions)\n",
    "val_f1 = f1_score(val_labels, val_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters and configurations for multiple models\n",
    "models = []\n",
    "vocab_size = 10000\n",
    "embedding_dim_list = [100, 200, 300]  # Different embedding dimensions\n",
    "num_filters_list = [50, 100, 150]    # Different numbers of filters\n",
    "filter_sizes_list = [(3, 100), (4, 100), (5, 100)]  # Different filter sizes\n",
    "num_classes = 2  # Number of output classes (e.g., binary classification)\n",
    "\n",
    "# Initialize models with different configurations\n",
    "for embedding_dim in embedding_dim_list:\n",
    "    for num_filters in num_filters_list:\n",
    "        for filter_sizes in filter_sizes_list:\n",
    "            model = TextCNN(vocab_size, embedding_dim, num_filters, filter_sizes, num_classes)\n",
    "            models.append(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
