{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a85b6ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading datasets...\n",
      "INFO:root:Vocabulary size: 42932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                             | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb torch.Size([73, 100, 80])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('The `preds` and `target` should have the same shape,', ' got `preds` with shape=torch.Size([73, 18]) and `target` with shape=torch.Size([73, 100]).')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 221\u001b[0m\n\u001b[1;32m    217\u001b[0m     state \u001b[38;5;241m=\u001b[39m State(model, optim, scheduler)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(nb_epochs)):\n\u001b[0;32m--> 221\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moov_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpad_tokenID\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m     evaluate_model(state\u001b[38;5;241m.\u001b[39mmodel, train_loader, criterion, epoch, writer)\n\u001b[1;32m    223\u001b[0m     state\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[55], line 152\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, epoch, writer, oov_rate, pad_tokenID)\u001b[0m\n\u001b[1;32m    150\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    151\u001b[0m     writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss/train\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m.\u001b[39mitem() ,  epoch\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader) \u001b[38;5;241m+\u001b[39mi )\n\u001b[0;32m--> 152\u001b[0m     writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy/train\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43maccuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43msoft\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m ,  epoch \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;241m+\u001b[39mi )\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/master/deepdac/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master/deepdac/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/master/deepdac/env/lib/python3.10/site-packages/torchmetrics/metric.py:298\u001b[0m, in \u001b[0;36mMetric.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_full_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_reduce_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache\n",
      "File \u001b[0;32m~/master/deepdac/env/lib/python3.10/site-packages/torchmetrics/metric.py:367\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# allow grads for batch computation\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m batch_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[0;32m~/master/deepdac/env/lib/python3.10/site-packages/torchmetrics/metric.py:457\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 457\u001b[0m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[0;32m~/master/deepdac/env/lib/python3.10/site-packages/torchmetrics/classification/stat_scores.py:322\u001b[0m, in \u001b[0;36mMulticlassStatScores.update\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update state with predictions and targets.\"\"\"\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_args:\n\u001b[0;32m--> 322\u001b[0m     \u001b[43m_multiclass_stat_scores_tensor_validation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultidim_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m preds, target \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_format(preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k)\n\u001b[1;32m    326\u001b[0m tp, fp, tn, fn \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_update(\n\u001b[1;32m    327\u001b[0m     preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultidim_average, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index\n\u001b[1;32m    328\u001b[0m )\n",
      "File \u001b[0;32m~/master/deepdac/env/lib/python3.10/site-packages/torchmetrics/functional/classification/stat_scores.py:292\u001b[0m, in \u001b[0;36m_multiclass_stat_scores_tensor_validation\u001b[0;34m(preds, target, num_classes, multidim_average, ignore_index)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m target\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m target\u001b[38;5;241m.\u001b[39mshape:\n\u001b[0;32m--> 292\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    293\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `preds` and `target` should have the same shape,\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    294\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m got `preds` with shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpreds\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and `target` with shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    295\u001b[0m         )\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multidim_average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    298\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `preds` and `target` have the same shape, the shape of `preds` should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m atleast 2D when multidim_average is set to `samplewise`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: ('The `preds` and `target` should have the same shape,', ' got `preds` with shape=torch.Size([73, 18]) and `target` with shape=torch.Size([73, 100]).')"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datamaestro import prepare_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchmetrics\n",
    "import torch\n",
    "from typing import List\n",
    "import time\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "ds = prepare_dataset('org.universaldependencies.french.gsd')\n",
    "\n",
    "\n",
    "# Format de sortie décrit dans\n",
    "# https://pypi.org/project/conllu/\n",
    "\n",
    "class Vocabulary:\n",
    "    \"\"\"Permet de gérer un vocabulaire.\n",
    "\n",
    "    En test, il est possible qu'un mot ne soit pas dans le\n",
    "    vocabulaire : dans ce cas le token \"__OOV__\" est utilisé.\n",
    "    Attention : il faut tenir compte de cela lors de l'apprentissage !\n",
    "\n",
    "    Utilisation:\n",
    "\n",
    "    - en train, utiliser v.get(\"blah\", adding=True) pour que le mot soit ajouté\n",
    "      automatiquement s'il n'est pas connu\n",
    "    - en test, utiliser v[\"blah\"] pour récupérer l'ID du mot (ou l'ID de OOV)\n",
    "    \"\"\"\n",
    "    OOVID = 1\n",
    "    PAD = 0\n",
    "\n",
    "    def __init__(self, oov: bool):\n",
    "        \"\"\" oov : autorise ou non les mots OOV \"\"\"\n",
    "        self.oov =  oov\n",
    "        self.id2word = [ \"PAD\"]\n",
    "        self.word2id = { \"PAD\" : Vocabulary.PAD}\n",
    "        if oov:\n",
    "            self.word2id[\"__OOV__\"] = Vocabulary.OOVID\n",
    "            self.id2word.append(\"__OOV__\")\n",
    "\n",
    "    def __getitem__(self, word: str):\n",
    "        if self.oov:\n",
    "            return self.word2id.get(word, Vocabulary.OOVID)\n",
    "        return self.word2id[word]\n",
    "\n",
    "    def get(self, word: str, adding=True):\n",
    "        try:\n",
    "            return self.word2id[word]\n",
    "        except KeyError:\n",
    "            if adding:\n",
    "                wordid = len(self.id2word)\n",
    "                self.word2id[word] = wordid\n",
    "                self.id2word.append(word)\n",
    "                return wordid\n",
    "            if self.oov:\n",
    "                return Vocabulary.OOVID\n",
    "            raise\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id2word)\n",
    "\n",
    "    def getword(self,idx: int):\n",
    "        if idx < len(self):\n",
    "            return self.id2word[idx]\n",
    "        return None\n",
    "\n",
    "    def getwords(self,idx: List[int]):\n",
    "        return [self.getword(i) for i in idx]\n",
    "\n",
    "\n",
    "\n",
    "class TaggingDataset():\n",
    "    def __init__(self, data, words: Vocabulary, tags: Vocabulary, adding=True):\n",
    "        self.sentences = []\n",
    "\n",
    "        for s in data:\n",
    "            self.sentences.append(([words.get(token[\"form\"], adding) for token in s], [tags.get(token[\"upostag\"], adding) for token in s]))\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    def __getitem__(self, ix):\n",
    "        return self.sentences[ix]\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Collate using pad_sequence\"\"\"\n",
    "    return tuple(pad_sequence([torch.LongTensor(b[j]) for b in batch]) for j in range(2))\n",
    "\n",
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, vocab_size, *args, **kwargs):\n",
    "        super().__init__(*args,**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, input_size, padding_idx =0)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input_seq):\n",
    "        embedded = self.embedding(input_seq)\n",
    "        print('emb',embedded.shape)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        output = self.fc(lstm_out)\n",
    "        return output\n",
    "\n",
    "\n",
    "class State :\n",
    "    def __init__(self, model, optim,scheduler) :\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.epoch, self.iteration = 0,0\n",
    "        self.scheduler = scheduler\n",
    "'''\n",
    "def deactivate_words(X, oov_rate):\n",
    "    random_values = torch.rand(X.shape)\n",
    "    mask = (random_values < oov_rate) and (inputs != Vocabulary.PAD)\n",
    "    modified_tensor = original_tensor.masked_fill(mask, 1)\n",
    "    return modified_tensor\n",
    "'''\n",
    "\n",
    "def deactivate_words(X, oov_rate, pad_token_id):\n",
    "    # Generate a random tensor with the same shape as X\n",
    "    random_values = torch.rand(X.shape).to(device)\n",
    "    \n",
    "    # Create a mask for the random values less than oov_rate\n",
    "    # and where X is not equal to pad_token_id (assuming PAD tokens should not be masked)\n",
    "    mask = (random_values < oov_rate).to(device) * (X != pad_token_id).to(device)\n",
    "    \n",
    "    # Replace masked values with the ID for OOV (which is 1 here)\n",
    "    modified_X = X.masked_fill(mask, 1)\n",
    "    \n",
    "    return modified_X\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, epoch,writer,oov_rate, pad_tokenID ):\n",
    "    model.train()\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        inputs,targets = inputs.to(device), targets.to(device)\n",
    "        inputs = deactivate_words(inputs,oov_rate, pad_tokenID)\n",
    "        outputs = model(inputs)\n",
    "        targets_hot = torch.nn.functional.one_hot(targets, num_classes=len(tags)).float()\n",
    "        loss = criterion(outputs, targets_hot)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        writer.add_scalar(\"Loss/train\", loss.item() ,  epoch*len(train_loader) +i )\n",
    "        writer.add_scalar(\"Accuracy/train\", accuracy(soft(outputs).argmax(1),targets) ,  epoch * len(train_loader)+i )\n",
    "    print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "def evaluate_model(model, train_loader, criterion, epoch,writer):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs,targets = inputs.to(device), targets.to(device)\n",
    "            inputs = deactivate_words(inputs,oov_rate, pad_tokenID)\n",
    "            outputs = model(inputs)\n",
    "            targets_hot = torch.nn.functional.one_hot(targets, num_classes=len(tags)).float()\n",
    "            loss = criterion(outputs, targets_hot)\n",
    "            writer.add_scalar(\"Loss/test\", loss.item() ,  epoch*len(train_loader) +i )\n",
    "            writer.add_scalar(\"Accuracy/test\", accuracy(soft(outputs).argmax(1),targets) ,  epoch * len(train_loader)+i )\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
    "            \n",
    "\n",
    "logging.info(\"Loading datasets...\")\n",
    "words = Vocabulary(True)\n",
    "tags = Vocabulary(False)\n",
    "train_data = TaggingDataset(ds.train, words, tags, True)\n",
    "dev_data = TaggingDataset(ds.validation, words, tags, True)\n",
    "test_data = TaggingDataset(ds.test, words, tags, False)\n",
    "\n",
    "\n",
    "logging.info(\"Vocabulary size: %d\", len(words))\n",
    "\n",
    "\n",
    "BATCH_SIZE=100\n",
    "\n",
    "train_loader = DataLoader(train_data, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dev_loader = DataLoader(dev_data, collate_fn=collate_fn, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_data, collate_fn=collate_fn, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  TODO:  Implémenter le modèle et la boucle d'apprentissage (en utilisant les LSTMs de pytorch)\n",
    "\n",
    "# paramètre\n",
    "writer = SummaryWriter(\"seq/\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=len(tags))\n",
    "PATH = '/home/pidoux/master/deepdac/AMAL/TME4/data/'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size = 80\n",
    "hidden_size = 50\n",
    "output_size = len(tags)\n",
    "vocab_size = len(words)\n",
    "nb_epochs = 5\n",
    "oov_rate = 0.1\n",
    "lr = 0.01\n",
    "pad_tokenID = 0\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "soft = nn.Softmax(dim=-1) ###### peut etre à changer\n",
    "print(f\"running on {device}\")\n",
    "\n",
    "savepath = Path(\"seq2seq.pch\")\n",
    "if savepath.is_file():\n",
    "    with savepath.open(\"rb\") as fp:\n",
    "        state = torch.load(fp)\n",
    "else:\n",
    "    model = Seq2SeqModel(input_size, hidden_size, output_size, vocab_size)\n",
    "    model = model.to(device)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optim, step_size=1, gamma=0.9)\n",
    "    state = State(model, optim, scheduler)\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(nb_epochs)):\n",
    "    train_model(state.model, train_loader, criterion, state.optim, epoch, writer, oov_rate,pad_tokenID)\n",
    "    evaluate_model(state.model, train_loader, criterion, epoch, writer)\n",
    "    state.scheduler.step()\n",
    "print('fin')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8438c2c4-b5a5-4e94-bf89-114fb346be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X,Y in train_loader :\n",
    "    print(X.shape)\n",
    "    torch.rand(\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a14ce4c6-95d4-4d4a-84b5-19f5e50a66b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42932"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceac525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import unicodedata\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import time\n",
    "import re\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "FILE = \"data/en-fra.txt\"\n",
    "\n",
    "writer = SummaryWriter(\"/tmp/runs/tag-\"+time.asctime())\n",
    "\n",
    "def normalize(s):\n",
    "    return re.sub(' +',' ', \"\".join(c if c in string.ascii_letters else \" \"\n",
    "         for c in unicodedata.normalize('NFD', s.lower().strip())\n",
    "         if  c in string.ascii_letters+\" \"+string.punctuation)).strip()\n",
    "\n",
    "\n",
    "class Vocabulary:\n",
    "    \"\"\"Permet de gérer un vocabulaire.\n",
    "\n",
    "    En test, il est possible qu'un mot ne soit pas dans le\n",
    "    vocabulaire : dans ce cas le token \"__OOV__\" est utilisé.\n",
    "    Attention : il faut tenir compte de cela lors de l'apprentissage !\n",
    "\n",
    "    Utilisation:\n",
    "\n",
    "    - en train, utiliser v.get(\"blah\", adding=True) pour que le mot soit ajouté\n",
    "      automatiquement\n",
    "    - en test, utiliser v[\"blah\"] pour récupérer l'ID du mot (ou l'ID de OOV)\n",
    "    \"\"\"\n",
    "    PAD = 0\n",
    "    EOS = 1\n",
    "    SOS = 2\n",
    "    OOVID = 3\n",
    "\n",
    "    def __init__(self, oov: bool):\n",
    "        self.oov = oov\n",
    "        self.id2word = [\"PAD\", \"EOS\", \"SOS\"]\n",
    "        self.word2id = {\"PAD\": Vocabulary.PAD, \"EOS\": Vocabulary.EOS, \"SOS\": Vocabulary.SOS}\n",
    "        if oov:\n",
    "            self.word2id[\"__OOV__\"] = Vocabulary.OOVID\n",
    "            self.id2word.append(\"__OOV__\")\n",
    "\n",
    "    def __getitem__(self, word: str):\n",
    "        if self.oov:\n",
    "            return self.word2id.get(word, Vocabulary.OOVID)\n",
    "        return self.word2id[word]\n",
    "\n",
    "    def get(self, word: str, adding=True):\n",
    "        try:\n",
    "            return self.word2id[word]\n",
    "        except KeyError:\n",
    "            if adding:\n",
    "                wordid = len(self.id2word)\n",
    "                self.word2id[word] = wordid\n",
    "                self.id2word.append(word)\n",
    "                return wordid\n",
    "            if self.oov:\n",
    "                return Vocabulary.OOVID\n",
    "            raise\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id2word)\n",
    "\n",
    "    def getword(self, idx: int):\n",
    "        if idx < len(self):\n",
    "            return self.id2word[idx]\n",
    "        return None\n",
    "\n",
    "    def getwords(self, idx: List[int]):\n",
    "        return [self.getword(i) for i in idx]\n",
    "\n",
    "\n",
    "\n",
    "class TradDataset():\n",
    "    def __init__(self,data,vocOrig,vocDest,adding=True,max_len=10):\n",
    "        self.sentences =[]\n",
    "        for s in tqdm(data.split(\"\\n\")):\n",
    "            if len(s)<1:continue\n",
    "            orig,dest=map(normalize,s.split(\"\\t\")[:2])\n",
    "            if len(orig)>max_len: continue\n",
    "            self.sentences.append((torch.tensor([vocOrig.get(o) for o in orig.split(\" \")]+[Vocabulary.EOS]),torch.tensor([vocDest.get(o) for o in dest.split(\" \")]+[Vocabulary.EOS])))\n",
    "    def __len__(self):return len(self.sentences)\n",
    "    def __getitem__(self,i): return self.sentences[i]\n",
    "\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    orig,dest = zip(*batch)\n",
    "    o_len = torch.tensor([len(o) for o in orig])\n",
    "    d_len = torch.tensor([len(d) for d in dest])\n",
    "    return pad_sequence(orig),o_len,pad_sequence(dest),d_len\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "with open(FILE) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "lines = [lines[x] for x in torch.randperm(len(lines))]\n",
    "idxTrain = int(0.8*len(lines))\n",
    "\n",
    "vocEng = Vocabulary(True)\n",
    "vocFra = Vocabulary(True)\n",
    "MAX_LEN=100\n",
    "BATCH_SIZE=100\n",
    "\n",
    "datatrain = TradDataset(\"\".join(lines[:idxTrain]),vocEng,vocFra,max_len=MAX_LEN)\n",
    "datatest = TradDataset(\"\".join(lines[idxTrain:]),vocEng,vocFra,max_len=MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(datatrain, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(datatest, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "#  TODO:  Implémenter l'encodeur, le décodeur et la boucle d'apprentissage\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
