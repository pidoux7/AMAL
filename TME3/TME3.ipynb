{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "# Téléchargement des données\n",
    "\n",
    "from datamaestro import prepare_dataset\n",
    "ds = prepare_dataset(\"com.lecun.mnist\");\n",
    "train_images, train_labels = ds.train.images.data(), ds.train.labels.data()\n",
    "test_images, test_labels =  ds.test.images.data(), ds.test.labels.data()\n",
    "\n",
    "# Tensorboard : rappel, lancer dans une console tensorboard --logdir runs\n",
    "writer = SummaryWriter(\"runs/runs\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "# Pour visualiser\n",
    "# Les images doivent etre en format Channel (3) x Hauteur x Largeur\n",
    "images = torch.tensor(train_images[0:8]).unsqueeze(1).repeat(1,3,1,1).double()/255.\n",
    "# Permet de fabriquer une grille d'images\n",
    "images = make_grid(images)\n",
    "# Affichage avec tensorboard\n",
    "writer.add_image(f'samples', images, 0)\n",
    "\n",
    "\n",
    "savepath = Path(\"model.pch\")\n",
    "\n",
    "\n",
    "class MonDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        label = self.labels[index]\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(test_images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 \tLoss: 0.162738\n",
      "Train Epoch: 1 \tLoss: 0.068157\n",
      "Train Epoch: 2 \tLoss: 0.161976\n",
      "Train Epoch: 3 \tLoss: 0.036995\n",
      "Train Epoch: 4 \tLoss: 0.046881\n",
      "Train Epoch: 5 \tLoss: 0.004175\n",
      "Train Epoch: 6 \tLoss: 0.013480\n",
      "Train Epoch: 7 \tLoss: 0.001900\n",
      "Train Epoch: 8 \tLoss: 0.088509\n",
      "Train Epoch: 9 \tLoss: 0.001741\n",
      "Train Epoch: 0 \tLoss: 0.207830\n",
      "Train Epoch: 1 \tLoss: 0.187557\n",
      "Train Epoch: 2 \tLoss: 0.122038\n",
      "Train Epoch: 3 \tLoss: 0.154844\n",
      "Train Epoch: 4 \tLoss: 0.146669\n",
      "Train Epoch: 5 \tLoss: 0.054450\n",
      "Train Epoch: 6 \tLoss: 0.091944\n",
      "Train Epoch: 7 \tLoss: 0.010414\n",
      "Train Epoch: 8 \tLoss: 0.020707\n",
      "Train Epoch: 9 \tLoss: 0.026456\n",
      "Train Epoch: 0 \tLoss: 0.226050\n",
      "Train Epoch: 1 \tLoss: 0.245057\n",
      "Train Epoch: 2 \tLoss: 0.155329\n",
      "Train Epoch: 3 \tLoss: 0.144343\n",
      "Train Epoch: 4 \tLoss: 0.189168\n",
      "Train Epoch: 5 \tLoss: 0.068299\n",
      "Train Epoch: 6 \tLoss: 0.084418\n",
      "Train Epoch: 7 \tLoss: 0.045084\n",
      "Train Epoch: 8 \tLoss: 0.107420\n",
      "Train Epoch: 9 \tLoss: 0.044527\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_sizes = [32, 128, 256]\n",
    "log_interval = 100\n",
    "\n",
    "input_size = 28 * 28  \n",
    "hidden_size = 128  \n",
    "output_size = 10  \n",
    "\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    print(\"\\nsize : \", batch_size)\n",
    "    train_loader = DataLoader(MonDataset(train_images, train_labels), batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(input_size, hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_size, output_size)\n",
    "    )\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()  \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images = images.reshape(-1, 28 * 28)/255.\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, encoding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 784  \n",
    "encoding_dim = 32  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on cpu\n"
     ]
    }
   ],
   "source": [
    "input_dim = 784  \n",
    "encoding_dim = 32 \n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "n_hidden = 20\n",
    "\n",
    "lr = 0.01\n",
    "batch_size = 100\n",
    "iterations = 10\n",
    "\n",
    "train_loader = DataLoader(MonDataset(train_images, train_labels), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(MonDataset(test_images, test_labels), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "device = torch.device( 'cuda ' if torch.cuda.is_available() else 'cpu' )\n",
    "print(f\"running on {device}\")\n",
    "class State :\n",
    "    def __init__(self, model, optim) :\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.epoch, self.iteration = 0,0\n",
    "\n",
    "if savepath.is_file():\n",
    "    with savepath.open(\"rb\") as fp:\n",
    "        state = torch.load(fp)\n",
    "else:\n",
    "    model = Autoencoder(input_dim, encoding_dim)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    state = State(model, optimizer)\n",
    "for epoch in range(iterations):\n",
    "    for x,y in train_loader:\n",
    "        x = x.reshape(-1, 28 * 28)/255.\n",
    "        state.optim.zero_grad()\n",
    "        x = x.to(device)\n",
    "        outputs = state.model(x)\n",
    "        loss = criterion(outputs, x)\n",
    "        loss.backward()\n",
    "        state.optim.step()\n",
    "        state.iteration += 1\n",
    "    with savepath.open(\"wb\") as fp:\n",
    "        state.epoch += 1\n",
    "        torch.save(state, fp)\n",
    "    with torch.no_grad():\n",
    "        for x, _ in test_loader:\n",
    "            x = x.reshape(-1, 28 * 28)/255.\n",
    "            x = x.to(device)\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, x)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
