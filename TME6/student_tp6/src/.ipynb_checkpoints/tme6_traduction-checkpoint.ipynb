{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 18:20:18.296548: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-18 18:20:18.296653: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-18 18:20:18.296714: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-18 18:20:18.313402: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-18 18:20:19.899764: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn.functional import pad\n",
    "import torch\n",
    "import unicodedata\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "FILE = \"../data/en-fra.txt\"\n",
    "\n",
    "writer = SummaryWriter(\"/tmp/runs/tag-\"+time.asctime())\n",
    "\n",
    "def normalize(s):\n",
    "    return re.sub(' +',' ', \"\".join(c if c in string.ascii_letters else \" \"\n",
    "         for c in unicodedata.normalize('NFD', s.lower().strip())\n",
    "         if  c in string.ascii_letters+\" \"+string.punctuation)).strip()\n",
    "\n",
    "\n",
    "class Vocabulary:\n",
    "    \"\"\"Permet de gérer un vocabulaire.\n",
    "\n",
    "    En test, il est possible qu'un mot ne soit pas dans le\n",
    "    vocabulaire : dans ce cas le token \"__OOV__\" est utilisé.\n",
    "    Attention : il faut tenir compte de cela lors de l'apprentissage !\n",
    "\n",
    "    Utilisation:\n",
    "\n",
    "    - en train, utiliser v.get(\"blah\", adding=True) pour que le mot soit ajouté\n",
    "      automatiquement\n",
    "    - en test, utiliser v[\"blah\"] pour récupérer l'ID du mot (ou l'ID de OOV)\n",
    "    \"\"\"\n",
    "    PAD = 0\n",
    "    EOS = 1\n",
    "    SOS = 2\n",
    "    OOVID = 3\n",
    "\n",
    "    def __init__(self, oov: bool):\n",
    "        self.oov = oov\n",
    "        self.id2word = [\"PAD\", \"EOS\", \"SOS\"]\n",
    "        self.word2id = {\"PAD\": Vocabulary.PAD, \"EOS\": Vocabulary.EOS, \"SOS\": Vocabulary.SOS}\n",
    "        if oov:\n",
    "            self.word2id[\"__OOV__\"] = Vocabulary.OOVID\n",
    "            self.id2word.append(\"__OOV__\")\n",
    "\n",
    "    def __getitem__(self, word: str):\n",
    "        if self.oov:\n",
    "            return self.word2id.get(word, Vocabulary.OOVID)\n",
    "        return self.word2id[word]\n",
    "\n",
    "    def get(self, word: str, adding=True):\n",
    "        try:\n",
    "            return self.word2id[word]\n",
    "        except KeyError:\n",
    "            if adding:\n",
    "                wordid = len(self.id2word)\n",
    "                self.word2id[word] = wordid\n",
    "                self.id2word.append(word)\n",
    "                return wordid\n",
    "            if self.oov:\n",
    "                return Vocabulary.OOVID\n",
    "            raise\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id2word)\n",
    "\n",
    "    def getword(self, idx: int):\n",
    "        if idx < len(self):\n",
    "            return self.id2word[idx]\n",
    "        return None\n",
    "\n",
    "    def getwords(self, idx: List[int]):\n",
    "        return [self.getword(i) for i in idx]\n",
    "\n",
    "\n",
    "\n",
    "class TradDataset():\n",
    "    def __init__(self,data,vocOrig,vocDest,adding=True,max_len=10):\n",
    "        self.sentences =[]\n",
    "        for s in tqdm(data.split(\"\\n\")):\n",
    "            if len(s)<1:continue\n",
    "            orig,dest=map(normalize,s.split(\"\\t\")[:2])\n",
    "            if len(orig)>max_len: continue\n",
    "            self.sentences.append((torch.tensor([vocOrig.get(o) for o in orig.split(\" \")]+[Vocabulary.EOS]),torch.tensor([vocDest.get(o) for o in dest.split(\" \")]+[Vocabulary.EOS])))\n",
    "    def __len__(self):return len(self.sentences)\n",
    "    def __getitem__(self,i): return self.sentences[i]\n",
    "\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    orig,dest = zip(*batch)\n",
    "    o_len = torch.tensor([len(o) for o in orig])\n",
    "    d_len = torch.tensor([len(d) for d in dest])\n",
    "    return pad_sequence(orig),o_len,pad_sequence(dest),d_len\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 136521/136521 [00:29<00:00, 4678.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 34132/34132 [00:06<00:00, 5278.09it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "with open(FILE) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "lines = [lines[x] for x in torch.randperm(len(lines))]\n",
    "idxTrain = int(0.8*len(lines))\n",
    "\n",
    "vocEng = Vocabulary(True)\n",
    "vocFra = Vocabulary(True)\n",
    "MAX_LEN=100\n",
    "BATCH_SIZE=100\n",
    "\n",
    "datatrain = TradDataset(\"\".join(lines[:idxTrain]),vocEng,vocFra,max_len=MAX_LEN)\n",
    "datatest = TradDataset(\"\".join(lines[idxTrain:]),vocEng,vocFra,max_len=MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(datatrain, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(datatest, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "#  TODO:  Implémenter l'encodeur, le décodeur et la boucle d'apprentissage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_enc, dim_latent_enc, dim_hidden_enc, pad_index):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_emb =  nn.Embedding(vocab_enc, dim_latent_enc, padding_idx=pad_index) \n",
    "        self.enc_gru = nn.GRU(dim_latent_enc, dim_hidden_enc)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_emb = self.enc_emb(x)\n",
    "        _, h_n = self.enc_gru(x_emb)\n",
    "        return h_n\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_dec, dim_latent_dec, dim_hidden_dec, pad_index) :\n",
    "        super(Decoder, self).__init__()\n",
    "        self.vocab_dec = vocab_dec\n",
    "        self.dec_emb =  nn.Embedding(vocab_dec, dim_latent_dec, padding_idx = pad_index) \n",
    "        self.dec_gru = nn.GRU(dim_latent_dec, dim_hidden_dec)\n",
    "        self.decode = nn.Linear(dim_hidden_dec, vocab_dec) \n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        emb = self.dec_emb(x)\n",
    "        _, h_n = self.dec_gru(emb, hidden)\n",
    "        dec = self.decode(h_n)   \n",
    "        return h_n, dec \n",
    "    \n",
    "    def generate(self, hidden, lenseq=None, use_teacher_forcing=False, target=None):\n",
    "        sos = Vocabulary.SOS\n",
    "        eos = Vocabulary.EOS\n",
    "\n",
    "        batch_size = hidden.shape[1] \n",
    "                \n",
    "        trad = torch.full((1, batch_size), sos, dtype=torch.long, device=hidden.device)\n",
    "        trad = torch.nn.functional.one_hot(trad, num_classes=self.vocab_dec)\n",
    "        x = torch.full((1, batch_size), sos, dtype=torch.long, device=hidden.device)\n",
    "\n",
    "        ht = hidden \n",
    "        i = 0\n",
    "        cpt_eos = 0\n",
    "        \n",
    "        while lenseq==None or i<lenseq :\n",
    "            ht, dec = self.forward(x, ht)\n",
    "            output = nn.functional.softmax(dec, dim=1)\n",
    "\n",
    "            x = torch.argmax(output, axis = 2).reshape(1,-1)\n",
    "            \n",
    "            if use_teacher_forcing : \n",
    "                trad = torch.cat((trad, output), dim = 0)\n",
    "                x = target[i,:].reshape(1,-1)\n",
    "            else : \n",
    "                trad = torch.cat((trad, output), dim = 0)\n",
    "\n",
    "            cpt_eos += torch.sum(x==eos).item()\n",
    "            if cpt_eos ==  batch_size: \n",
    "                break\n",
    "            i+=1\n",
    "\n",
    "        return trad[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(encoder, decoder, criterion, train_loader, test_loader, teacher_forcing_prob = 0.5 , lr=0.3, epoch = 10 ):\n",
    "\n",
    "    writer = SummaryWriter(\"traduction/\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "\n",
    "    parameters = list(encoder.parameters()) + list(decoder.parameters())\n",
    "    optimizer = torch.optim.Adam(params = parameters, lr = lr)\n",
    "\n",
    "\n",
    "    liste_loss_train = []\n",
    "    liste_loss_val = []\n",
    "    for epoch in tqdm(range(epoch)):\n",
    "        \n",
    "        liste_loss_batch = []\n",
    "\n",
    "        for input_seq, idx_pad_input, target_seq, idx_pad_target in tqdm(train_loader):\n",
    "            input_seq , idx_pad_input, target_seq, idx_pad_target = input_seq.to(device) , idx_pad_input.to(device), target_seq.to(device), idx_pad_target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            use_teacher_forcing = True if torch.rand(1).item() < teacher_forcing_prob else False\n",
    "            hidden = encoder(input_seq).to(device)\n",
    "            yhat = decoder.generate(hidden, lenseq=torch.max(idx_pad_target), use_teacher_forcing=use_teacher_forcing, target=target_seq)\n",
    "            yhat = torch.nn.functional.pad(yhat,  (0, target_seq.size(1) - yhat.size(1)), value=Vocabulary.PAD).to(dtype=torch.float32)\n",
    "            yhat = torch.transpose(yhat,1,2)\n",
    "\n",
    "            loss = criterion(yhat, target_seq)\n",
    "\n",
    "            writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                liste_loss_batch.append(loss.item())\n",
    "            \n",
    "        liste_loss_train.append(np.mean(liste_loss_batch))\n",
    "\n",
    "        print(\"it\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            liste_loss_batch = []\n",
    "\n",
    "            for input_seq, idx_pad_input, target_seq, idx_pad_target in test_loader:\n",
    "                input_seq , idx_pad_input, target_seq, idx_pad_target = input_seq.to(device) , idx_pad_input.to(device), target_seq.to(device), idx_pad_target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                use_teacher_forcing = True if torch.rand(1).item() < teacher_forcing_prob else False\n",
    "                hidden = encoder(input_seq).to(device)\n",
    "                yhat = decoder.generate(hidden, lenseq=torch.max(idx_pad_target), use_teacher_forcing=use_teacher_forcing, target=target_seq)\n",
    "                yhat = torch.nn.functional.pad(yhat,  (0, target_seq.size(1) - yhat.size(1)), value=Vocabulary.PAD).to(dtype=torch.float32)\n",
    "                yhat = torch.transpose(yhat,1,2)\n",
    "\n",
    "                loss = criterion(yhat, target_seq)\n",
    "\n",
    "                writer.add_scalar(\"Loss/test\", loss, epoch)\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                optimizer.step()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    liste_loss_batch.append(loss.item())\n",
    "                    \n",
    "            liste_loss_val.append(np.mean(liste_loss_batch))\n",
    " \n",
    "\n",
    "        print(\"val\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(len(liste_loss_train)), liste_loss_train, label='Loss train', color='tab:orange')\n",
    "    plt.plot(np.arange(len(liste_loss_val)), liste_loss_val, label='Loss val', color='tab:blue')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.title(\"Loss en train et en validation\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                | 0/10 [00:00<?, ?it/s]\n",
      "  0%|                                                                                              | 0/1365 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                                                    | 1/1365 [00:06<2:37:34,  6.93s/it]\u001b[A\n",
      "  0%|                                                                                    | 2/1365 [00:14<2:46:57,  7.35s/it]\u001b[A\n",
      "  0%|▏                                                                                   | 3/1365 [00:21<2:46:41,  7.34s/it]\u001b[A\n",
      "  0%|▏                                                                                   | 4/1365 [00:47<4:29:40, 11.89s/it]\u001b[A\n",
      "  0%|                                                                                                | 0/10 [00:47<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m decoder \u001b[38;5;241m=\u001b[39m Decoder(vocab_dec, dim_latent_dec, dim_hidden, pad_index)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     16\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(ignore_index\u001b[38;5;241m=\u001b[39mVocabulary\u001b[38;5;241m.\u001b[39mPAD)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 34\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(encoder, decoder, criterion, train_loader, test_loader, teacher_forcing_prob, lr, epoch)\u001b[0m\n\u001b[1;32m     31\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 34\u001b[0m         liste_loss_batch\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     36\u001b[0m liste_loss_train\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(liste_loss_batch))\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "vocab_enc = vocEng.__len__()  \n",
    "dim_latent_enc = 10\n",
    "dim_hidden = 5\n",
    "\n",
    "vocab_dec = vocFra.__len__() \n",
    "dim_latent_dec = 10\n",
    "\n",
    "pad_index = Vocabulary.PAD\n",
    "lr = 0.3\n",
    "\n",
    "\n",
    "encoder = Encoder(vocab_enc, dim_latent_enc, dim_hidden, pad_index).to(device)\n",
    "decoder = Decoder(vocab_dec, dim_latent_dec, dim_hidden, pad_index).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=Vocabulary.PAD)\n",
    "train(encoder, decoder, criterion, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traduction(sentence, encoder, decoder):\n",
    "    x = torch.tensor([vocEng.__getitem__(w) for w in sentence.split()]).reshape(-1,1)\n",
    "    hidden = encoder(x)\n",
    "    trad = decoder.generate(hidden, lenseq=20)\n",
    "    trad = torch.argmax(trad, axis = 2).reshape(-1)\n",
    "    return \" \".join(vocFra.getwords(trad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n"
     ]
    }
   ],
   "source": [
    "sentence = \"hello i love cats and also dogs\"\n",
    "trad = traduction(sentence, encoder, decoder)\n",
    "print(trad)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
